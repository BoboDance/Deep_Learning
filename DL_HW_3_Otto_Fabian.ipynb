{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        # Training data\n",
    "        self.mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "        # Image params\n",
    "        self.n_channels = 1\n",
    "        self.image_width = 28\n",
    "        self.image_height = 28\n",
    "\n",
    "        # Training params\n",
    "        self.n_classes = 10\n",
    "        self.n_iter = 10000\n",
    "        self.batch_size = 50\n",
    "        self.activation = tf.nn.relu\n",
    "\n",
    "        # Kernel/filter and pooling params\n",
    "        self.kernel_conv = [5, 5]\n",
    "        self.kernel_pool = [2, 2]\n",
    "        self.padding = 2\n",
    "        self.stride = 1\n",
    "        self.n_filters_1 = 6\n",
    "        self.n_filters_2 = 16\n",
    "        self.stride_pool = 2\n",
    "\n",
    "        # Dense params\n",
    "        self.n_dense_1 = 120\n",
    "        self.n_dense_2 = 84\n",
    "\n",
    "        # Data placeholder for training or test batches\n",
    "        self.x = tf.placeholder(tf.float32,\n",
    "                                shape=[self.batch_size, self.image_width, self.image_height, self.n_channels])\n",
    "        self.y_ = tf.placeholder(tf.float32, shape=[self.batch_size, self.n_classes])\n",
    "\n",
    "        # Convolutional layer #1 kernels/filters and bias\n",
    "        self.kernel_conv_1 = self.weight_variable(self.kernel_conv + [self.n_channels] + [self.n_filters_1])\n",
    "        self.bias_conv_1 = self.bias_variable([self.n_filters_1])\n",
    "\n",
    "        # Convolutional layer #2 kernels/filters and bias\n",
    "        self.kernel_conv_2 = self.weight_variable(self.kernel_conv + [self.n_filters_1] + [self.n_filters_2])\n",
    "        self.bias_conv_2 = self.bias_variable([self.n_filters_2])\n",
    "\n",
    "        # Dense layer #1 weights\n",
    "        # W_dense_1 is dependent on the output size of the pool2 layer and is defined there\n",
    "        self.W_dense_1 = None\n",
    "        self.b_dense_1 = self.bias_variable((self.n_dense_1,))\n",
    "\n",
    "        # Dense layer #2 weights\n",
    "        self.W_dense_2 = self.weight_variable((self.n_dense_1, self.n_dense_2))\n",
    "        self.b_dense_2 = self.bias_variable((self.n_dense_2,))\n",
    "\n",
    "        # Dense layer #3 weights\n",
    "        self.W_dense_3 = self.weight_variable((self.n_dense_2, self.n_classes))\n",
    "        self.b_dense_3 = self.bias_variable((self.n_classes,))\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        # sess = tf.InteractiveSession()\n",
    "\n",
    "        # Convolutional layer #1\n",
    "        #conv1 = self.convolutional_layer(input_tensor=self.x, kernel=self.kernel_conv_1, bias=self.bias_conv_1,\n",
    "         #                                stride=self.stride, padding=self.padding)\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(\n",
    "            inputs=self.x,\n",
    "            filters=self.n_filters_1,\n",
    "            kernel_size=[5, 5],\n",
    "            strides = (2,2),\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        \n",
    "        # Average pooling layer #1\n",
    "        #pool1 = self.avg_pooling_layer(input_tensor=conv1, kernel=self.kernel_pool, padding=0,\n",
    "         #                              stride=self.stride_pool)\n",
    "    \n",
    "        pool1 = tf.layers.average_pooling2d(inputs=conv1, pool_size=self.kernel_pool, strides=self.stride_pool)\n",
    "\n",
    "\n",
    "\n",
    "        # Convolutional layer #2\n",
    "       # conv2 = self.convolutional_layer(input_tensor=pool1, kernel=self.kernel_conv_2, bias=self.bias_conv_2,\n",
    "        #                                 stride=self.stride, padding=0)\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=self.n_filters_2,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"valid\",\n",
    "            activation=tf.nn.relu)\n",
    "\n",
    "        # Average pooling layer #2\n",
    "       # pool2 = self.avg_pooling_layer(input_tensor=conv2, kernel=self.kernel_pool, padding=0,\n",
    "        #                               stride=self.stride_pool)\n",
    "        \n",
    "        pool1 = tf.layers.average_pooling2d(inputs=conv2, pool_size=self.kernel_pool, strides=self.stride_pool)\n",
    "\n",
    "        \n",
    "        # define size of dense_1 based on pool2 output\n",
    "        pool2_size = pool2.get_shape().as_list()\n",
    "        self.W_dense_1 = self.weight_variable([pool2_size[1] * pool2_size[2] * self.n_filters_2, self.n_dense_1])\n",
    "        pool2 = tf.reshape(pool2, [-1, pool2_size[1] * pool2_size[2] * self.n_filters_2])\n",
    "        \n",
    "        dense1 = tf.layers.dense(inputs=pool2, units=self.n_dense_1, activation=tf.nn.relu)\n",
    "        dense2 = tf.layers.dense(inputs=dense1, units=self.n_dense_2, activation=tf.nn.relu)\n",
    "        logits = tf.layers.dense(inputs=dense2, units=self.n_classes, activation=tf.nn.relu)\n",
    "\n",
    "        # Dense layer #1\n",
    "       # dense1 = self.dense_layer(input_tensor=pool2, w=self.W_dense_1, b=self.b_dense_1)\n",
    "\n",
    "        # Dense layer #2\n",
    "       # dense2 = self.dense_layer(input_tensor=dense1, w=self.W_dense_2, b=self.b_dense_2)\n",
    "\n",
    "        # Dense layer #3 / Logits layer\n",
    "        #logits = self.dense_layer(input_tensor=dense2, w=self.W_dense_3, b=self.b_dense_3)\n",
    "\n",
    "        # compute cross entroy for training\n",
    "        cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.y_, logits=logits))\n",
    "        optimizer = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(self.y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(self.n_iter):\n",
    "                batch = self.mnist.train.next_batch(self.batch_size)\n",
    "                x = np.reshape(batch[0], (self.batch_size, 28, 28, 1))\n",
    "                if i % 100 == 0:\n",
    "                    train_accuracy = accuracy.eval(feed_dict={self.x: x, self.y_: batch[1]})\n",
    "                    print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "                    optimizer.run(feed_dict={self.x: x, self.y_: batch[1]})\n",
    "\n",
    "            test_size = self.mnist.test.images.shape[0]\n",
    "            acc = []\n",
    "            for i in range(test_size // self.batch_size):\n",
    "                batch = self.mnist.test.next_batch(self.batch_size)\n",
    "                x = np.reshape(batch[0], (self.batch_size, 28, 28, 1))\n",
    "                acc.append(accuracy.eval(feed_dict={self.x: x, self.y_: batch[1]}))\n",
    "\n",
    "            print('test accuracy {}'.format(np.array(acc).mean()))\n",
    "\n",
    "    def convolutional_layer(self, input_tensor, kernel, bias, stride, padding):\n",
    "        # get input and filter dimensions\n",
    "        n, height, width, channel = input_tensor.get_shape().as_list()\n",
    "        filter_height, filter_width, filter_channel, filter_n = kernel.get_shape().as_list()\n",
    "\n",
    "        # calculate output dimensions after convolution\n",
    "        out_height = (height + 2 * padding - filter_height) // stride + 1\n",
    "        out_width = (width + 2 * padding - filter_width) // stride + 1\n",
    "\n",
    "        # flatten X and W for matrix multiplication\n",
    "        x_flat = self.flatten(input_tensor, filter_height, filter_width, filter_channel, out_height, out_width, stride,\n",
    "                              padding)\n",
    "        w_flat = tf.reshape(kernel, [filter_height * filter_width * filter_channel, filter_n])\n",
    "\n",
    "        # compute matrix multiplication\n",
    "        z = tf.nn.xw_plus_b(x_flat, w_flat, bias)\n",
    "\n",
    "        # reverse flatten and apply activation\n",
    "        return self.activation(tf.transpose(tf.reshape(z, [out_height, out_width, n, filter_n]), [2, 0, 1, 3]))\n",
    "\n",
    "    def avg_pooling_layer(self, input_tensor, kernel, padding, stride):\n",
    "        # n, heigth, width, channel = [d.value for d in input_tensor.get_shape()]\n",
    "        n, heigth, width, channel = input_tensor.get_shape()\n",
    "\n",
    "        pool_height = kernel[0]\n",
    "        pool_width = kernel[1]\n",
    "\n",
    "        out_height = (heigth + 2 * padding - pool_height) // stride + 1\n",
    "        out_width = (width + 2 * padding - pool_width) // stride + 1\n",
    "\n",
    "        X_flat = self.flatten(input_tensor, pool_height, pool_width, channel, out_height, out_width, stride, padding)\n",
    "\n",
    "        pool = tf.reduce_mean(tf.reshape(X_flat, [out_height, out_width, n, pool_height * pool_width, channel]), axis=3)\n",
    "        return tf.transpose(pool, [2, 0, 1, 3])\n",
    "\n",
    "    def dense_layer(self, input_tensor, w, b):\n",
    "        return self.activation(tf.nn.xw_plus_b(input_tensor, w, b))\n",
    "\n",
    "    @staticmethod\n",
    "    def flatten(input_tensor, window_height, window_width, window_channel, out_height, out_width, stride,\n",
    "                padding):\n",
    "\n",
    "        # apply padding on image width and height and no padding on image and channel level\n",
    "        X_padded = tf.pad(input_tensor, [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n",
    "\n",
    "        # iterate over height and width while taking stride into account\n",
    "        # ignore image and channel dimensions\n",
    "        windows = []\n",
    "        for y in range(out_height):\n",
    "            for x in range(out_width):\n",
    "                windows.append(\n",
    "                    tf.slice(X_padded, [0, y * stride, x * stride, 0],\n",
    "                             [-1, window_height, window_width, -1]))\n",
    "        # shape : [out_height * out_width, n, filter_height, filter_width, channel]\n",
    "        stacked = tf.stack(windows)\n",
    "\n",
    "        # return as 2D Tensor\n",
    "        # second dimension contains value of one \"stride\"\n",
    "        return tf.reshape(stacked, [-1, window_channel * window_width * window_height])\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_variable(shape):\n",
    "        return tf.Variable(tf.truncated_normal(shape=shape, stddev=0.1))\n",
    "\n",
    "    @staticmethod\n",
    "    def bias_variable(shape):\n",
    "        return tf.Variable(tf.constant(.1, shape=shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'pool2' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0e81de7d3dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-58b0953f1ccc>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# define size of dense_1 based on pool2 output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mpool2_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_dense_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpool2_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpool2_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_filters_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dense_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mpool2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool2_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpool2_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_filters_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'pool2' referenced before assignment"
     ]
    }
   ],
   "source": [
    "LeNet().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
